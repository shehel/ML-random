{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Checking directory \n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "#reference to imp directories\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/statefarm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils; importlib.reload(utils)\n",
    "from utils import *\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vgg16bn; importlib.reload(vgg16bn)\n",
    "from vgg16bn import Vgg16BN\n",
    "vgg = Vgg16BN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "path = DATA_HOME_DIR+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating Validation set based on drivers. \n",
    "Need to have separate drivers in validation and train set to prevent overfitting based on drivers. Drivers aren't important but their actions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    os.mkdir(valid_path+'c'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drivers = df.groupby('subject').groups.keys()\n",
    "print (drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('driver_imgs_list.csv')\n",
    "drivers = df.groupby('subject').groups.keys()\n",
    "print (drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "driver = df.loc[df['subject'] == 'p049']\n",
    "for index, row in driver.iterrows():\n",
    "    location = row[1]+'/'\n",
    "    name = row[2]\n",
    "    fname = train_path+location+name\n",
    "    if (os.path.isfile(fname)):\n",
    "        os.rename(train_path+location+name, valid_path+location+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setting folder locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "test_path = path + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + 'train/'\n",
    "valid_path=path + 'valid/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Moving data to appropriate directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "paths = glob('*/')\n",
    "print (paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Making validation set and all other sets. Switch between copyfile and os.rename as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in paths:\n",
    "    tpath = train_path+i\n",
    "    npath = sample_path+i\n",
    "    %mkdir $npath\n",
    "    %cd $tpath\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(1000): copyfile(shuf[i], npath+shuf[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creating sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%cd $fulltest\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(30): copyfile(shuf[i], test_path+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create single 'unknown' class for test set\n",
    "%cd $DATA_HOME_DIR/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, steps_per_epoch=int(np.ceil(batches.samples/64)), nb_epoch=1, validation_data=val_batches, \n",
    "                     validation_steps=int(np.ceil(val_batches.samples/64)))\n",
    "    #model.optimizer.lr = 0.001\n",
    "    #model.fit_generator(batches, steps_per_epoch=int(np.ceil(batches.samples/64)), nb_epoch=1, validation_data=val_batches, \n",
    "     #                validation_steps=int(np.ceil(val_batches.samples/64)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test(self, path, batch_size=8):\n",
    "        print(path)\n",
    "        test_batches = get_batches(self, path, shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "        print (test_batches.samples)\n",
    "        return test_batches, self.model.predict_generator(test_batches, int(np.ceil(test_batches.samples/batch_size)))\n",
    "def get_batches(self, path, gen=image.ImageDataGenerator(), shuffle=False, batch_size=8, class_mode='categorical'):\n",
    "        return gen.flow_from_directory(path, target_size=(224,224),\n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batches, preds = test(bn_model, test_path, batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_array(results_path+'test_preds.dat', preds)\n",
    "save_array(results_path+'filenames.dat', batches.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = get_batches(valid_path, batch_size=batch_size)\n",
    "test_batches = get_batches(test_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Vgg16 without BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = vgg.model\n",
    "# Here, [-1] means that, fetch the last element from the array returned by the for loop\n",
    "#last_conv_idx = [i for i, l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "#conv_layers = model.layers[:last_conv_idx+1]\n",
    "#conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $results_path\n",
    "rm -R conv*.dat\n",
    "%cd $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conv_feat2 = model.predict_generator(batches, np.ceil(batches.samples/batch_size))\n",
    "#conv_val_feat2 = model.predict_generator(val_batches, np.ceil(val_batches.samples/batch_size))\n",
    "#conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PreCalculating convolution features for train, val and test data to speed up computations. The precalculated features are stored in bcolz array [due to shortage of RAM] and written to disk to free up RAM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = results_path+'conv_featFinalxx.dat'\n",
    "for i in range(batches.n // batch_size+1):\n",
    "    conv_feat = model.predict_on_batch(batches.next()[0])\n",
    "    if not i:\n",
    "        c = bcolz.carray(conv_feat, rootdir=fname, mode='a')\n",
    "    else:\n",
    "        c.append(conv_feat)\n",
    "    c.shape\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = results_path+'conv_val_featFinalxx.dat'\n",
    "for i in range(val_batches.n // batch_size+1):\n",
    "    conv_val_feat = model.predict_on_batch(val_batches.next()[0])\n",
    "    if not i:\n",
    "        c = bcolz.carray(conv_val_feat, rootdir=fname, mode='a')\n",
    "    else:\n",
    "        c.append(conv_val_feat)\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = results_path+'conv_test_featFinalxx.dat'\n",
    "for i in range(test_batches.n // batch_size+1):\n",
    "    conv_test_feat = conv_model.predict_on_batch(test_batches.next()[0])\n",
    "    if not i:\n",
    "        c = bcolz.carray(conv_test_feat, rootdir=fname, mode='a')\n",
    "    else:\n",
    "        c.append(conv_test_feat)\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "#conv_val_feat2 = load_array(path+'results/conv_val_y.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = results_path+'conv_val_yFinalxx.dat'\n",
    "save_array(fname, val_labels)\n",
    "fname = results_path+'conv_train_yFinalxx.dat'\n",
    "save_array(fname, trn_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post pre-calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=bcolz.open(results_path+'conv_featFinalxx.dat', mode='r')\n",
    "y= bcolz.open(results_path+'conv_train_yFinalxx.dat', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valX=bcolz.open(results_path+'conv_val_featFinalxx.dat', mode='r')\n",
    "valy= bcolz.open(results_path+'conv_val_yFinalxx.dat', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_batches=BcolzArrayIterator(X,y, batch_size=batch_size, shuffle=True)\n",
    "vl_batches=BcolzArrayIterator(valX,valy, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX=bcolz.open(path+'results/conv_test_featFinal.dat', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_batches=BcolzArrayIterator(testX, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bn_model.predict(conv_val_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense layers on pretrained conv layers\n",
    "Edit: VGG with Batchnorm using batchnorm-vgg trained model and weights. http://files.fast.ai/models/\n",
    "\n",
    "Train: 18509\n",
    "Validate: 3915\n",
    "Test:  79726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_batches.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=model.output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "bn_model.fit(conv_feat2, trn_labels, batch_size=batch_size, nb_epoch=30, \n",
    "             validation_data=(conv_val_feat2, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.fit_generator(trn_batches, nb_epoch=10, steps_per_epoch=np.ceil(trn_batches.N/batch_size), validation_data=vl_batches, \n",
    "                     validation_steps=int(np.ceil(vl_batches.N/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01\n",
    "bn_model.fit_generator(trn_batches, nb_epoch=10, steps_per_epoch=np.ceil(trn_batches.N/batch_size), validation_data=vl_batches, \n",
    "                     validation_steps=int(np.ceil(vl_batches.N/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/conv8_1Final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pseudo = bn_model.predict_generator(tst_batches, steps=np.ceil(tst_batches.N/batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "test_pseudo[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_pseudo = np.concatenate([trn_labels, test_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1=bcolz.open(path+'results/conv_featFinal.dat', mode='r')\n",
    "trn_batches=BcolzArrayIterator(X1, batch_size=batch_size, shuffle=False)\n",
    "trn_batches.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2=bcolz.open(path+'results/conv_test_featFinal.dat', mode='r')\n",
    "tst_batches=BcolzArrayIterator(X2, batch_size=batch_size, shuffle=False)\n",
    "tst_batches.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = path+'results/conv_feat_extFinal.dat'\n",
    "batch = trn_batches.next()\n",
    "c = bcolz.carray(batch, rootdir=fname, mode='w')\n",
    "for i in range(trn_batches.N // batch_size):\n",
    "    batch = trn_batches.next()\n",
    "    c.append(batch)\n",
    "for i in range(tst_batches.N // batch_size+1):\n",
    "    batch = tst_batches.next()\n",
    "    c.append(batch)\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X3=bcolz.open(path+'results/conv_feat_extFinal.dat', mode='r')\n",
    "\n",
    "X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = path+'results/conv_ptest_yFinal.dat'\n",
    "save_array(fname, comb_pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_pseudo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre calculated features and train on train+test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pX=bcolz.open(path+'results/conv_feat_extFinal.dat', mode='r')\n",
    "py= bcolz.open(path+'results/conv_ptest_yFinal.dat', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tstComb_batches=BcolzArrayIterator(pX, py, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(path+'models/conv8_1Final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.001\n",
    "bn_model.fit_generator(tstComb_batches, nb_epoch=10, steps_per_epoch=np.ceil(tstComb_batches.N/batch_size), validation_data=vl_batches, \n",
    "                     validation_steps=int(np.ceil(vl_batches.N/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01\n",
    "bn_model.fit_generator(tstComb_batches, nb_epoch=10, steps_per_epoch=np.ceil(tstComb_batches.N/batch_size), validation_data=vl_batches, \n",
    "                     validation_steps=int(np.ceil(vl_batches.N/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.metrics.categorical_crossentropy(val_labels, do_clip(preds, 0.9050)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pX=bcolz.open(path+'results/conv_test_feat.dat', mode='r')\n",
    "tst_batches=BcolzArrayIterator(pX, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = bn_model.predict_generator(tst_batches, steps=np.ceil(tst_batches.N/batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(test_pred,0.8840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "subm_name = path+'results/subm2.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'img', [a[8:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making submissions, old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n",
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "print (filenames[1], probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = vgg.get_batches(test_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "filenames = batches.filenames\n",
    "a = []\n",
    "\n",
    "for idx, val in enumerate(filenames):\n",
    "    a.append(val[8:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(val_batches.class_indices, key=val_batches.class_indices.get)\n",
    "submission = pd.DataFrame(preds, columns=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (submission)\n",
    "submission['img']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = submission.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "submission= submission[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('firstSubVGG', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = load_array('/home/hearth/ML/course/courses/deeplearning1/nbs/data/dogscats/' + 'test_preds.dat')\n",
    "filenames = load_array('/home/hearth/ML/course/courses/deeplearning1/nbs/data/dogscats/' + 'filenames.dat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
