{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7003 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX 1080 Ti (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano.gpuarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils; importlib.reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Activation\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Nietzche dataset: https://s3.amazonaws.com/text-datasets/nietzsche.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/rnn/'\n",
    "path = DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'nietzsche.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total Characters:  58\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print ('total Characters: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   ! \" \\' ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; = ? [ ] _ a b c d e f g h i j k l m n o p q r s t u v w x'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Characters used in the text\n",
    "' '.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idx turns text into list of numbers based on above mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Character model - predicting the 4th\n",
    "RNN unrolled form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600893"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 character model\n",
    "cs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_dat = [idx[i] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c2_dat = [idx[i] for i in range(1, len(idx)-1-cs, cs)]\n",
    "c3_dat = [idx[i] for i in range(2, len(idx)-1-cs, cs)]\n",
    "#The character we want to predict\n",
    "c4_dat = [idx[i] for i in range(3, len(idx)-1-cs, cs)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-1])\n",
    "x3 = np.stack(c3_dat[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200295,), (200295,), (200295,), (200295,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape,x2.shape, x3.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factors = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='float64', name=name)\n",
    "    emb = Embedding(n_in, n_out, input_length=1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input('c1', vocab_size, factors)\n",
    "c2_in, c2 = embedding_input('c2', vocab_size, factors)\n",
    "c3_in, c3 = embedding_input('c3', vocab_size, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Activations in layer operation from input to hidden\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First hidden activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_hidden = Dense(n_hidden, activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \"\"\"\n",
      "/opt/anaconda/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "c2_dense=dense_in(c2)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "#Merging which is summing by default adds the orange and\n",
    "#green arrow operations\n",
    "c2_hidden = merge([c2_dense, hidden_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "c3_dense = dense_in(c3)\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_hidden = merge([c3_dense, hidden_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be the size of the total characters we have in 1 hot encoded format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4_out = dense_out(c3_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c1_in, c2_in, c3_in], c4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.3504     \n",
      "Epoch 2/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.2449     \n",
      "Epoch 3/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.1999     \n",
      "Epoch 4/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.1535     \n",
      "Epoch 5/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.1169     \n",
      "Epoch 6/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.0920     \n",
      "Epoch 7/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.0770     \n",
      "Epoch 8/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.0672     \n",
      "Epoch 9/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.0594     \n",
      "Epoch 10/10\n",
      "200295/200295 [==============================] - 2s - loss: 2.0529     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f721f545d68>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    prediction = np.argmax(p)\n",
    "    return chars[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN \n",
    "With 8 pieces of preceding words, predicting the 9th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+n] for i in range(0, len(idx)-1-cs, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[i+cs] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making numpy arrays\n",
    "xs = [np.stack(c[:-2]) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_ins = [embedding_input('c'+str(n), vocab_size, n_fac) for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_arch(n_hidden):\n",
    "    return (Dense(n_hidden, activation='relu'), \n",
    "            Dense(n_hidden, activation='relu', kernel_initializer='identity'),\n",
    "            Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in, dense_hidden, dense_output = create_arch(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = dense_in(c_ins[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75109/75109 [==============================] - 1s - loss: 2.4074     \n",
      "Epoch 2/12\n",
      "75109/75109 [==============================] - 1s - loss: 2.1719     \n",
      "Epoch 3/12\n",
      "75109/75109 [==============================] - 1s - loss: 2.0795     \n",
      "Epoch 4/12\n",
      "75109/75109 [==============================] - 2s - loss: 2.0121     \n",
      "Epoch 5/12\n",
      "75109/75109 [==============================] - 1s - loss: 1.9593     \n",
      "Epoch 6/12\n",
      "75109/75109 [==============================] - 1s - loss: 1.9138     \n",
      "Epoch 7/12\n",
      "75109/75109 [==============================] - 1s - loss: 1.8734     \n",
      "Epoch 8/12\n",
      "75109/75109 [==============================] - 1s - loss: 1.8377     \n",
      "Epoch 9/12\n",
      "75109/75109 [==============================] - 1s - loss: 1.8076     \n",
      "Epoch 10/12\n",
      "75109/75109 [==============================] - 1s - loss: 1.7808     \n",
      "Epoch 11/12\n",
      "75109/75109 [==============================] - 1s - loss: 1.7561     \n",
      "Epoch 12/12\n",
      "75109/75109 [==============================] - 1s - loss: 1.7323     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7214924710>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size=64, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('. i am a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting chars 2 to n using chars 1 to n-1\n",
    "More backpropagation means more feedback. Limited context through sequence of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a label matrix that includes every element after the first\n",
    "#because the first element will predict 2nd and so on\n",
    "c_out_dat = [[idx[i+n] for i in range(1, len(idx)-cs, cs)]\n",
    "            for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since first char has gone into the loop, the initial state must be initialised somehow. This is done through an input of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp1 = Input(shape=(n_fac,), name='zeros')\n",
    "hidden = dense_in(inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/opt/anaconda/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "outs = []\n",
    "\n",
    "for i in range(cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden], mode='sum')\n",
    "    #Ever layer has an output now\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp1] + [c[0] for c in c_ins], outs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75109, 42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.tile(np.zeros(n_fac), (len(xs[0]), 1))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75109/75109 [==============================] - 3s - loss: 19.0761 - dense_3_loss_1: 2.5827 - dense_3_loss_2: 2.4787 - dense_3_loss_3: 2.4242 - dense_3_loss_4: 2.4127 - dense_3_loss_5: 2.4156 - dense_3_loss_6: 2.4047 - dense_3_loss_7: 2.3961 - dense_3_loss_8: 1.9613     \n",
      "Epoch 2/12\n",
      "75109/75109 [==============================] - 3s - loss: 17.4323 - dense_3_loss_1: 2.4528 - dense_3_loss_2: 2.3174 - dense_3_loss_3: 2.1951 - dense_3_loss_4: 2.1517 - dense_3_loss_5: 2.1378 - dense_3_loss_6: 2.1248 - dense_3_loss_7: 2.1191 - dense_3_loss_8: 1.9335     \n",
      "Epoch 3/12\n",
      "75109/75109 [==============================] - 3s - loss: 16.9924 - dense_3_loss_1: 2.4434 - dense_3_loss_2: 2.2991 - dense_3_loss_3: 2.1442 - dense_3_loss_4: 2.0783 - dense_3_loss_5: 2.0498 - dense_3_loss_6: 2.0382 - dense_3_loss_7: 2.0381 - dense_3_loss_8: 1.9013     \n",
      "Epoch 4/12\n",
      "75109/75109 [==============================] - 3s - loss: 16.7187 - dense_3_loss_1: 2.4398 - dense_3_loss_2: 2.2928 - dense_3_loss_3: 2.1175 - dense_3_loss_4: 2.0353 - dense_3_loss_5: 1.9953 - dense_3_loss_6: 1.9796 - dense_3_loss_7: 1.9837 - dense_3_loss_8: 1.8746     \n",
      "Epoch 5/12\n",
      "75109/75109 [==============================] - 3s - loss: 16.5150 - dense_3_loss_1: 2.4373 - dense_3_loss_2: 2.2896 - dense_3_loss_3: 2.1003 - dense_3_loss_4: 2.0019 - dense_3_loss_5: 1.9546 - dense_3_loss_6: 1.9372 - dense_3_loss_7: 1.9417 - dense_3_loss_8: 1.8524     \n",
      "Epoch 6/12\n",
      "75109/75109 [==============================] - 3s - loss: 16.3479 - dense_3_loss_1: 2.4361 - dense_3_loss_2: 2.2870 - dense_3_loss_3: 2.0891 - dense_3_loss_4: 1.9773 - dense_3_loss_5: 1.9208 - dense_3_loss_6: 1.9001 - dense_3_loss_7: 1.9073 - dense_3_loss_8: 1.8302     \n",
      "Epoch 7/12\n",
      "75109/75109 [==============================] - 3s - loss: 16.2052 - dense_3_loss_1: 2.4354 - dense_3_loss_2: 2.2848 - dense_3_loss_3: 2.0796 - dense_3_loss_4: 1.9548 - dense_3_loss_5: 1.8939 - dense_3_loss_6: 1.8705 - dense_3_loss_7: 1.8759 - dense_3_loss_8: 1.8104     \n",
      "Epoch 8/12\n",
      "75109/75109 [==============================] - 3s - loss: 16.0827 - dense_3_loss_1: 2.4342 - dense_3_loss_2: 2.2841 - dense_3_loss_3: 2.0723 - dense_3_loss_4: 1.9400 - dense_3_loss_5: 1.8699 - dense_3_loss_6: 1.8440 - dense_3_loss_7: 1.8477 - dense_3_loss_8: 1.7904     \n",
      "Epoch 9/12\n",
      "75109/75109 [==============================] - 3s - loss: 15.9789 - dense_3_loss_1: 2.4339 - dense_3_loss_2: 2.2833 - dense_3_loss_3: 2.0679 - dense_3_loss_4: 1.9261 - dense_3_loss_5: 1.8499 - dense_3_loss_6: 1.8217 - dense_3_loss_7: 1.8224 - dense_3_loss_8: 1.7737     \n",
      "Epoch 10/12\n",
      "75109/75109 [==============================] - 3s - loss: 15.8899 - dense_3_loss_1: 2.4335 - dense_3_loss_2: 2.2821 - dense_3_loss_3: 2.0631 - dense_3_loss_4: 1.9146 - dense_3_loss_5: 1.8351 - dense_3_loss_6: 1.8028 - dense_3_loss_7: 1.8027 - dense_3_loss_8: 1.7560     \n",
      "Epoch 11/12\n",
      "75109/75109 [==============================] - 3s - loss: 15.8134 - dense_3_loss_1: 2.4326 - dense_3_loss_2: 2.2817 - dense_3_loss_3: 2.0604 - dense_3_loss_4: 1.9050 - dense_3_loss_5: 1.8199 - dense_3_loss_6: 1.7872 - dense_3_loss_7: 1.7849 - dense_3_loss_8: 1.7416     \n",
      "Epoch 12/12\n",
      "75109/75109 [==============================] - 3s - loss: 15.7448 - dense_3_loss_1: 2.4326 - dense_3_loss_2: 2.2801 - dense_3_loss_3: 2.0561 - dense_3_loss_4: 1.8973 - dense_3_loss_5: 1.8070 - dense_3_loss_6: 1.7724 - dense_3_loss_7: 1.7701 - dense_3_loss_8: 1.7293     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72116a67b8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros]+xs, ys, batch_size=64, epochs=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]]+arrs)\n",
    "    print (list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'p', 'a', 'r', 't', ' ', 'o', 'f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'o', 'r', 'e', 'i', 'o', 'f', ' ']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' part of')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencial model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 42, 8, 58)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden, n_fac, cs, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs),\n",
    "        #Return sequence = true puts output into the loop as in the \n",
    "        #case above.\n",
    "        SimpleRNN(n_hidden, return_sequences=True, activation='relu', recurrent_initializer='identity'),\n",
    "        #Since the RNN above predicts 8 variables, we might expect the\n",
    "        #dense layer to accomodate this as well - this function is served by the below layer.\n",
    "        #In this case, there is 8 dense layers sharing same weight matrix.\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75109, 8), (75109, 8, 1))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn=np.stack(np.squeeze(xs), axis=1)\n",
    "y_rnn=np.atleast_3d(np.stack(ys, axis=1))\n",
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/keras/models.py:852: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 0s - loss: 2.4924     \n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 0s - loss: 2.0362     \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 0s - loss: 1.9106     \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 0s - loss: 1.8404     \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 0s - loss: 1.7942     \n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 0s - loss: 1.7617     \n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 0s - loss: 1.7373     \n",
      "Epoch 8/8\n",
      "75109/75109 [==============================] - 0s - loss: 1.7184     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7209dc4fd0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size=128, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    #arrs will now be one dimensional array input with each \n",
    "    #idxs being an element in array of arrays \n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p=model.predict(arrs)[0]\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 'n', ' ', 'i', 's', ' ']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful models\n",
    "\n",
    "Goal is a model with long term dependency. \n",
    "1. Stop shuffling(shuffle=true) the data when fitting so that the model isn't prevented from learning long term dependencies.\n",
    "2. Stop passing in array of zeros as initialisation steps for subsequent loop cycles. This will allow the model to build up arbitarily long dependencies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=cs, batch_input_shape=(bs, 8)),\n",
    "    #To normalise inputs (exploding gradients)\n",
    "    BatchNormalization(),\n",
    "    #Setting stateful to true makes the model leave the hidden activations as \n",
    "    #it is after every sequence of 8 in this case. \n",
    "    LSTM(n_hidden, return_sequences=True, stateful=True),\n",
    "    TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn)//bs*bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75072\n"
     ]
    }
   ],
   "source": [
    "print (mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75072/75072 [==============================] - 5s - loss: 2.1744     \n",
      "Epoch 2/4\n",
      "75072/75072 [==============================] - 5s - loss: 1.9190     \n",
      "Epoch 3/4\n",
      "75072/75072 [==============================] - 5s - loss: 1.8457     \n",
      "Epoch 4/4\n",
      "75072/75072 [==============================] - 5s - loss: 1.8028     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71ffca0c88>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffle is set to false to learn long term dependency\n",
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, epochs=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## One-hot sequence model - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(n_hidden, return_sequences=True, input_shape=(cs, vocab_size),\n",
    "             activation='relu', recurrent_initializer='identity'),\n",
    "    TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "])\n",
    "#Categorical cross entropy rather than sparse categorical.. is because the inputs are now \n",
    "#one hot encoded. \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode labels and data\n",
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn=np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn=np.stack(oh_xs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/keras/models.py:852: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 1s - loss: 2.3414     \n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 1s - loss: 1.9799     \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 1s - loss: 1.8725     \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 1s - loss: 1.8128     \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 1s - loss: 1.7729     \n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 1s - loss: 1.7440     \n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 1s - loss: 1.7230     \n",
      "Epoch 8/8\n",
      "75109/75109 [==============================] - 1s - loss: 1.7053     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71eda2dc50>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size=64, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_oh(inp):\n",
    "    idxs = np.array([char_indices[c] for c in inp])\n",
    "    arr = to_categorical(idxs, vocab_size)\n",
    "    p = model.predict(arr[np.newaxis,:])[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 's', 's', ' ']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________\n",
    "## Theano RNN\n",
    "Theano builds a computation graph before running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning variables\n",
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(rows, cols):\n",
    "    #Calculate the scale of the random numbers to use - Glorot init\n",
    "    scale = math.sqrt(2/rows)\n",
    "    #shared is a theano keyword that specifies that the data is something that will be\n",
    "    #passed to GPU and tracked there essentially making theano the possessor of this data\n",
    "    return shared(normal(scale=scale, size=(rows, cols)).astype(np.float32))\n",
    "def init_bias(rows):\n",
    "    vec = np.zeros(rows, dtype=np.float32)\n",
    "    return shared(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wgts_and_bias(n_in, n_out):\n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "def id_and_bias(n):\n",
    "    #Hidden states are initialised with an identity matrix\n",
    "    return shared(np.eye(n, dtype=np.float32)), init_bias(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights and bias to the hidden layer\n",
    "W_h = id_and_bias(n_hidden)\n",
    "#Weights and bias to the input layer\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "#Weigths and bias to the output layer\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Called on each step through \n",
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    #Activation of input and previous hidden state with their weights and biases\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    #Output calculation\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    #Return hidden state and output/prediction\n",
    "    return h, T.flatten(y, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theano.scan is for loops in theano with a possibility for parallelisation for a specific kind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Variables in the input, hidden and output stages of the step are defined\n",
    "#v_h and v_y will carry the returned values of step i.e., hidden state and output \n",
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                           outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining gradient desent in theano. Error holds the loss while g_all holds all the requires derivatives\n",
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr):\n",
    "    #OrderedDict maps everyone of the weights to its updated weights \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts, grads)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Each step involves the update represented below\n",
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75109"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:23.146\n",
      "error:20.265\n",
      "error:19.709\n",
      "error:18.805\n",
      "error:17.770\n",
      "error:18.196\n",
      "error:18.184\n",
      "error:17.594\n",
      "error:17.064\n",
      "error:17.192\n",
      "error:16.717\n",
      "error:16.821\n",
      "error:17.243\n",
      "error:16.549\n",
      "error:16.045\n",
      "error:16.777\n",
      "error:16.621\n",
      "error:16.312\n",
      "error:16.123\n",
      "error:15.996\n",
      "error:15.938\n",
      "error:15.635\n",
      "error:15.808\n",
      "error:15.529\n",
      "error:16.076\n",
      "error:15.778\n",
      "error:15.155\n",
      "error:15.708\n",
      "error:15.638\n",
      "error:15.700\n",
      "error:15.912\n",
      "error:15.731\n",
      "error:15.866\n",
      "error:15.728\n",
      "error:15.328\n",
      "error:15.907\n",
      "error:15.402\n",
      "error:15.603\n",
      "error:15.297\n",
      "error:15.491\n",
      "error:14.744\n",
      "error:15.162\n",
      "error:15.130\n",
      "error:15.269\n",
      "error:15.249\n",
      "error:15.214\n",
      "error:15.119\n",
      "error:15.441\n",
      "error:15.614\n",
      "error:15.671\n",
      "error:14.860\n",
      "error:15.055\n",
      "error:14.746\n",
      "error:14.579\n",
      "error:15.172\n",
      "error:14.928\n",
      "error:14.360\n",
      "error:15.044\n",
      "error:14.676\n",
      "error:14.575\n",
      "error:14.580\n",
      "error:15.000\n",
      "error:14.928\n",
      "error:14.632\n",
      "error:14.337\n",
      "error:14.341\n",
      "error:13.883\n",
      "error:14.396\n",
      "error:14.868\n",
      "error:14.480\n",
      "error:14.737\n",
      "error:14.408\n",
      "error:14.189\n",
      "error:14.229\n",
      "error:14.236\n"
     ]
    }
   ],
   "source": [
    "err = 0; l_rate=0.01\n",
    "\n",
    "#Gradient desent loop\n",
    "for i in range(len(X)):\n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    #Print out the error every 1000 times\n",
    "    if i%1000 == 999:\n",
    "        print (\"error:{:.3f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#New function that takes input with hiddenstate to produce an output rather than the loss to make predictions\n",
    "f_y = theano.function([t_h0, t_inp], v_y, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(f_y(np.zeros(n_hidden), X[6]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = np.argmax(X[6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 'n', '?', ' ', 'i', 's']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', ' ', ' ', ' ', 't', 'n', ' ']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
